{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, MLJ, MLJBase\n",
    "using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>16,751 rows × 145 columns (omitted printing of 138 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Node2Vec_1</th><th>Node2Vec_2</th><th>Node2Vec_3</th><th>Node2Vec_4</th><th>Node2Vec_5</th><th>Node2Vec_6</th><th>Node2Vec_7</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.189205</td><td>-0.68293</td><td>0.526686</td><td>0.530565</td><td>0.337738</td><td>0.158541</td><td>-0.61182</td></tr><tr><th>2</th><td>-0.168315</td><td>-0.495042</td><td>-0.140764</td><td>-0.582063</td><td>0.230374</td><td>-0.777822</td><td>0.737297</td></tr><tr><th>3</th><td>0.0296064</td><td>0.230097</td><td>-0.623636</td><td>0.204871</td><td>-0.564605</td><td>1.53592</td><td>0.346013</td></tr><tr><th>4</th><td>1.0129</td><td>1.16148</td><td>0.724457</td><td>0.363616</td><td>-0.560745</td><td>1.10423</td><td>0.482912</td></tr><tr><th>5</th><td>-0.716053</td><td>0.497655</td><td>0.0596283</td><td>0.887571</td><td>0.390334</td><td>0.566871</td><td>0.101913</td></tr><tr><th>6</th><td>-0.657151</td><td>0.40875</td><td>0.237709</td><td>-0.0985008</td><td>0.182429</td><td>0.973765</td><td>0.248399</td></tr><tr><th>7</th><td>-1.21038</td><td>0.11158</td><td>-0.617902</td><td>-0.46801</td><td>-1.47998</td><td>-0.795456</td><td>-0.0662079</td></tr><tr><th>8</th><td>0.0410683</td><td>-0.26366</td><td>0.219273</td><td>0.660439</td><td>0.372267</td><td>0.370671</td><td>-0.038241</td></tr><tr><th>9</th><td>1.55563</td><td>-0.67778</td><td>0.126633</td><td>0.000379588</td><td>1.24327</td><td>0.555104</td><td>0.298999</td></tr><tr><th>10</th><td>-0.138545</td><td>-0.981385</td><td>1.15403</td><td>0.0717479</td><td>-0.588679</td><td>0.00627843</td><td>2.14836</td></tr><tr><th>11</th><td>0.196416</td><td>-1.22784</td><td>-0.472843</td><td>0.10745</td><td>0.393278</td><td>-0.0287671</td><td>-0.518952</td></tr><tr><th>12</th><td>0.929993</td><td>-0.202287</td><td>0.02709</td><td>0.206246</td><td>1.21342</td><td>0.619932</td><td>1.1873</td></tr><tr><th>13</th><td>0.791565</td><td>-0.560336</td><td>0.159315</td><td>0.254002</td><td>-0.0411731</td><td>0.253673</td><td>0.548647</td></tr><tr><th>14</th><td>0.645016</td><td>-0.150325</td><td>0.692308</td><td>0.705642</td><td>-0.710867</td><td>0.171953</td><td>0.842101</td></tr><tr><th>15</th><td>0.172284</td><td>-1.19538</td><td>0.394264</td><td>1.28999</td><td>-0.798404</td><td>-0.438003</td><td>-0.166157</td></tr><tr><th>16</th><td>0.27356</td><td>-0.646405</td><td>0.0408181</td><td>-0.493749</td><td>-0.417111</td><td>0.546798</td><td>-0.953025</td></tr><tr><th>17</th><td>0.175882</td><td>-0.458487</td><td>-0.811681</td><td>-1.29085</td><td>-1.90505</td><td>0.428664</td><td>0.753196</td></tr><tr><th>18</th><td>0.723834</td><td>0.274802</td><td>0.108413</td><td>-0.368643</td><td>2.02414</td><td>-0.572263</td><td>-0.461395</td></tr><tr><th>19</th><td>0.850576</td><td>-1.0293</td><td>0.571217</td><td>0.376509</td><td>0.0765461</td><td>-0.147917</td><td>0.873665</td></tr><tr><th>20</th><td>-0.181179</td><td>-0.12616</td><td>0.271398</td><td>-0.211311</td><td>-0.235424</td><td>1.53018</td><td>0.385375</td></tr><tr><th>21</th><td>-1.4105</td><td>-0.363577</td><td>-0.187452</td><td>-0.41323</td><td>0.0148239</td><td>2.18192</td><td>1.21474</td></tr><tr><th>22</th><td>-0.408021</td><td>-0.20141</td><td>0.0912196</td><td>-0.39273</td><td>0.66929</td><td>0.874611</td><td>-0.425148</td></tr><tr><th>23</th><td>-0.233292</td><td>-0.194136</td><td>-0.13329</td><td>0.457249</td><td>-0.0512044</td><td>-0.725607</td><td>0.827228</td></tr><tr><th>24</th><td>0.406284</td><td>-0.897033</td><td>-0.409551</td><td>0.975807</td><td>0.164998</td><td>-0.0747044</td><td>0.107835</td></tr><tr><th>25</th><td>0.30879</td><td>-0.347924</td><td>-0.0595185</td><td>-0.0114238</td><td>-0.472397</td><td>0.610933</td><td>-0.102636</td></tr><tr><th>26</th><td>0.109294</td><td>-0.900798</td><td>0.025124</td><td>-1.22034</td><td>-0.361203</td><td>-1.03326</td><td>0.843446</td></tr><tr><th>27</th><td>0.667501</td><td>-0.836718</td><td>-0.522971</td><td>0.821904</td><td>-0.984279</td><td>-1.12084</td><td>-0.0690828</td></tr><tr><th>28</th><td>-0.373247</td><td>-0.792789</td><td>0.0535484</td><td>-0.218827</td><td>-0.274268</td><td>0.0561848</td><td>0.0364279</td></tr><tr><th>29</th><td>-0.0943334</td><td>-0.0637639</td><td>0.690954</td><td>1.21107</td><td>0.32415</td><td>0.142188</td><td>-0.639966</td></tr><tr><th>30</th><td>0.452438</td><td>-0.854872</td><td>-0.686519</td><td>1.15083</td><td>0.848485</td><td>-0.927083</td><td>-0.238739</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& Node2Vec\\_1 & Node2Vec\\_2 & Node2Vec\\_3 & Node2Vec\\_4 & Node2Vec\\_5 & Node2Vec\\_6 & Node2Vec\\_7 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.189205 & -0.68293 & 0.526686 & 0.530565 & 0.337738 & 0.158541 & -0.61182 & $\\dots$ \\\\\n",
       "\t2 & -0.168315 & -0.495042 & -0.140764 & -0.582063 & 0.230374 & -0.777822 & 0.737297 & $\\dots$ \\\\\n",
       "\t3 & 0.0296064 & 0.230097 & -0.623636 & 0.204871 & -0.564605 & 1.53592 & 0.346013 & $\\dots$ \\\\\n",
       "\t4 & 1.0129 & 1.16148 & 0.724457 & 0.363616 & -0.560745 & 1.10423 & 0.482912 & $\\dots$ \\\\\n",
       "\t5 & -0.716053 & 0.497655 & 0.0596283 & 0.887571 & 0.390334 & 0.566871 & 0.101913 & $\\dots$ \\\\\n",
       "\t6 & -0.657151 & 0.40875 & 0.237709 & -0.0985008 & 0.182429 & 0.973765 & 0.248399 & $\\dots$ \\\\\n",
       "\t7 & -1.21038 & 0.11158 & -0.617902 & -0.46801 & -1.47998 & -0.795456 & -0.0662079 & $\\dots$ \\\\\n",
       "\t8 & 0.0410683 & -0.26366 & 0.219273 & 0.660439 & 0.372267 & 0.370671 & -0.038241 & $\\dots$ \\\\\n",
       "\t9 & 1.55563 & -0.67778 & 0.126633 & 0.000379588 & 1.24327 & 0.555104 & 0.298999 & $\\dots$ \\\\\n",
       "\t10 & -0.138545 & -0.981385 & 1.15403 & 0.0717479 & -0.588679 & 0.00627843 & 2.14836 & $\\dots$ \\\\\n",
       "\t11 & 0.196416 & -1.22784 & -0.472843 & 0.10745 & 0.393278 & -0.0287671 & -0.518952 & $\\dots$ \\\\\n",
       "\t12 & 0.929993 & -0.202287 & 0.02709 & 0.206246 & 1.21342 & 0.619932 & 1.1873 & $\\dots$ \\\\\n",
       "\t13 & 0.791565 & -0.560336 & 0.159315 & 0.254002 & -0.0411731 & 0.253673 & 0.548647 & $\\dots$ \\\\\n",
       "\t14 & 0.645016 & -0.150325 & 0.692308 & 0.705642 & -0.710867 & 0.171953 & 0.842101 & $\\dots$ \\\\\n",
       "\t15 & 0.172284 & -1.19538 & 0.394264 & 1.28999 & -0.798404 & -0.438003 & -0.166157 & $\\dots$ \\\\\n",
       "\t16 & 0.27356 & -0.646405 & 0.0408181 & -0.493749 & -0.417111 & 0.546798 & -0.953025 & $\\dots$ \\\\\n",
       "\t17 & 0.175882 & -0.458487 & -0.811681 & -1.29085 & -1.90505 & 0.428664 & 0.753196 & $\\dots$ \\\\\n",
       "\t18 & 0.723834 & 0.274802 & 0.108413 & -0.368643 & 2.02414 & -0.572263 & -0.461395 & $\\dots$ \\\\\n",
       "\t19 & 0.850576 & -1.0293 & 0.571217 & 0.376509 & 0.0765461 & -0.147917 & 0.873665 & $\\dots$ \\\\\n",
       "\t20 & -0.181179 & -0.12616 & 0.271398 & -0.211311 & -0.235424 & 1.53018 & 0.385375 & $\\dots$ \\\\\n",
       "\t21 & -1.4105 & -0.363577 & -0.187452 & -0.41323 & 0.0148239 & 2.18192 & 1.21474 & $\\dots$ \\\\\n",
       "\t22 & -0.408021 & -0.20141 & 0.0912196 & -0.39273 & 0.66929 & 0.874611 & -0.425148 & $\\dots$ \\\\\n",
       "\t23 & -0.233292 & -0.194136 & -0.13329 & 0.457249 & -0.0512044 & -0.725607 & 0.827228 & $\\dots$ \\\\\n",
       "\t24 & 0.406284 & -0.897033 & -0.409551 & 0.975807 & 0.164998 & -0.0747044 & 0.107835 & $\\dots$ \\\\\n",
       "\t25 & 0.30879 & -0.347924 & -0.0595185 & -0.0114238 & -0.472397 & 0.610933 & -0.102636 & $\\dots$ \\\\\n",
       "\t26 & 0.109294 & -0.900798 & 0.025124 & -1.22034 & -0.361203 & -1.03326 & 0.843446 & $\\dots$ \\\\\n",
       "\t27 & 0.667501 & -0.836718 & -0.522971 & 0.821904 & -0.984279 & -1.12084 & -0.0690828 & $\\dots$ \\\\\n",
       "\t28 & -0.373247 & -0.792789 & 0.0535484 & -0.218827 & -0.274268 & 0.0561848 & 0.0364279 & $\\dots$ \\\\\n",
       "\t29 & -0.0943334 & -0.0637639 & 0.690954 & 1.21107 & 0.32415 & 0.142188 & -0.639966 & $\\dots$ \\\\\n",
       "\t30 & 0.452438 & -0.854872 & -0.686519 & 1.15083 & 0.848485 & -0.927083 & -0.238739 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m16751×145 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m Node2Vec_1 \u001b[0m\u001b[1m Node2Vec_2 \u001b[0m\u001b[1m Node2Vec_3 \u001b[0m\u001b[1m Node2Vec_4   \u001b[0m\u001b[1m Node2Vec_5  \u001b[0m\u001b[1m Node2V\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float6\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │  0.189205   -0.68293     0.526686    0.530565      0.337738     0.158 ⋯\n",
       "     2 │ -0.168315   -0.495042   -0.140764   -0.582063      0.230374    -0.777\n",
       "     3 │  0.0296064   0.230097   -0.623636    0.204871     -0.564605     1.535\n",
       "     4 │  1.0129      1.16148     0.724457    0.363616     -0.560745     1.104\n",
       "     5 │ -0.716053    0.497655    0.0596283   0.887571      0.390334     0.566 ⋯\n",
       "     6 │ -0.657151    0.40875     0.237709   -0.0985008     0.182429     0.973\n",
       "     7 │ -1.21038     0.11158    -0.617902   -0.46801      -1.47998     -0.795\n",
       "     8 │  0.0410683  -0.26366     0.219273    0.660439      0.372267     0.370\n",
       "     9 │  1.55563    -0.67778     0.126633    0.000379588   1.24327      0.555 ⋯\n",
       "    10 │ -0.138545   -0.981385    1.15403     0.0717479    -0.588679     0.006\n",
       "    11 │  0.196416   -1.22784    -0.472843    0.10745       0.393278    -0.028\n",
       "   ⋮   │     ⋮           ⋮           ⋮            ⋮             ⋮            ⋮ ⋱\n",
       " 16742 │  0.546666   -0.386842    0.0453089  -0.0939495     0.066136    -0.049\n",
       " 16743 │  0.0120699  -0.0730964   0.0266487   0.0651361    -0.00543487   0.027 ⋯\n",
       " 16744 │  0.268518    0.0550602   0.0595213   0.0906026    -0.0340651   -0.488\n",
       " 16745 │ -0.303978   -0.174769    0.207338    0.169801     -0.816864    -0.388\n",
       " 16746 │ -0.267024   -0.166337    0.43201    -0.079668      0.11784      0.064\n",
       " 16747 │  0.448821    0.0347565   0.167149    0.0486668    -0.362685    -0.222 ⋯\n",
       " 16748 │  0.354739    0.17449     0.0840973  -0.0394596     0.25351     -0.308\n",
       " 16749 │ -0.509287   -0.525154    0.262596   -0.694214     -0.484104    -0.337\n",
       " 16750 │  0.247451   -0.44979    -0.0677709   0.18479      -0.195539    -0.502\n",
       " 16751 │  0.0247097  -0.0653904   0.236023   -0.0025198    -0.100204     0.128 ⋯\n",
       "\u001b[36m                                              140 columns and 16730 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CSV.read(\"/Users/maurizio/WiSARDpy/datasets/biomat_clf.csv\", DataFrames.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1002, 11113, 13869, 955, 8632, 4242, 13517, 16658, 16045, 400  …  7946, 15281, 10587, 6954, 8493, 950, 13788, 10928, 16710, 7742], [4221, 8842, 3044, 6822, 10274, 9818, 15381, 9231, 11475, 253  …  376, 8346, 12170, 15812, 15131, 13483, 12883, 3894, 16744, 9391])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Array(DataFrames.select(df, Not([:label])))\n",
    "y = vec(Array(DataFrames.select(df, [:label])))\n",
    "train, test = MLJ.partition(eachindex(y), 0.8, shuffle=true, rng=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16751-element Vector{String3}:\n",
       " \"CS6\"\n",
       " \"CS4\"\n",
       " \"CS0\"\n",
       " \"CS6\"\n",
       " \"CS5\"\n",
       " \"CS6\"\n",
       " \"CS0\"\n",
       " \"CS5\"\n",
       " \"CS1\"\n",
       " \"CS4\"\n",
       " \"CS6\"\n",
       " \"CS3\"\n",
       " \"CS6\"\n",
       " ⋮\n",
       " \"CS6\"\n",
       " \"CS3\"\n",
       " \"CS6\"\n",
       " \"CS7\"\n",
       " \"CS6\"\n",
       " \"CS7\"\n",
       " \"CS7\"\n",
       " \"CS4\"\n",
       " \"CS4\"\n",
       " \"CS5\"\n",
       " \"CS6\"\n",
       " \"CS4\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(unique(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassification(LightGBM.Booster(Ptr{Nothing} @0x0000000000000000, LightGBM.Dataset[]), \"\", \"multiclass\", \"gbdt\", 5, 0.2, 1000, 10, \"serial\", 8, -1.0, 50, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2, 1.0, 1.0, 1.0, 0, 3, 0, false, 6, 255, 200000, 1, \"\", true, false, Int64[], true, true, false, true, 1.0, 1.0, 0.1, 50, 0.5, false, false, 4, 0.2, 0.1, 100, 32, 10.0, 10.0, [\"average_accuracy\"], 1, false, Int64[], 1, 12400, 120, \"\", 1, \"cpu\", false, -1, -1, 1, false, false)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster = LightGBM.LGBMClassification(;\n",
    "    objective=\"multiclass\", \n",
    "    metric=[\"average_accuracy\"], \n",
    "    num_leaves=1000, \n",
    "    learning_rate=0.2, \n",
    "    max_bin=255, \n",
    "    max_depth=10, \n",
    "    min_data_in_leaf=50, \n",
    "    num_iterations=5, \n",
    "    num_class=1, \n",
    "    use_missing=true, \n",
    "    min_sum_hessian_in_leaf=1.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching fit!(::LGBMClassification, ::Matrix{Float64}, ::Vector{String3}; num_classes=10)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit!(::LGBMEstimator, ::AbstractMatrix{TX}, \u001b[91m::Vector{Ty}\u001b[39m, \u001b[91m::Tuple{AbstractMatrix{TX}, Vector{Ty}}...\u001b[39m; verbosity, is_row_major, weights, init_score, truncate_booster) where {TX<:Real, Ty<:Real} at /Users/maurizio/.julia/packages/LightGBM/3367V/src/fit.jl:35\u001b[91m got unsupported keyword argument \"num_classes\"\u001b[39m\n\u001b[0m  fit!(::LGBMEstimator, \u001b[91m::LightGBM.Dataset\u001b[39m, \u001b[91m::LightGBM.Dataset...\u001b[39m; verbosity, truncate_booster) at /Users/maurizio/.julia/packages/LightGBM/3367V/src/fit.jl:70\u001b[91m got unsupported keyword argument \"num_classes\"\u001b[39m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching fit!(::LGBMClassification, ::Matrix{Float64}, ::Vector{String3}; num_classes=10)\n\u001b[0mClosest candidates are:\n\u001b[0m  fit!(::LGBMEstimator, ::AbstractMatrix{TX}, \u001b[91m::Vector{Ty}\u001b[39m, \u001b[91m::Tuple{AbstractMatrix{TX}, Vector{Ty}}...\u001b[39m; verbosity, is_row_major, weights, init_score, truncate_booster) where {TX<:Real, Ty<:Real} at /Users/maurizio/.julia/packages/LightGBM/3367V/src/fit.jl:35\u001b[91m got unsupported keyword argument \"num_classes\"\u001b[39m\n\u001b[0m  fit!(::LGBMEstimator, \u001b[91m::LightGBM.Dataset\u001b[39m, \u001b[91m::LightGBM.Dataset...\u001b[39m; verbosity, truncate_booster) at /Users/maurizio/.julia/packages/LightGBM/3367V/src/fit.jl:70\u001b[91m got unsupported keyword argument \"num_classes\"\u001b[39m",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[83]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "LightGBM.fit!(booster, X[train,:], y[train], num_classes = size(unique(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5857142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │     0.0     │     1.0     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│     0.0     │      2      │      0      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│     1.0     │     29      │     39      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = LightGBM.predict(booster, X[test,:])\n",
    "ŷ = replace(x->x>=0.5 ? 1.0 : 0.0, ŷ)\n",
    "accuracy = sum(ŷ .== y[test]) / length(y[test])\n",
    "println(\"accuracy: $accuracy\")\n",
    "ConfusionMatrix()(vec(ŷ), coerce(vec(y[test]), OrderedFactor)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
